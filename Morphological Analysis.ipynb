{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b35778f-afc7-41f7-b56c-2e51ee05c2dc",
   "metadata": {},
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd1c6c-0153-43cf-9268-3d72fe1628ca",
   "metadata": {},
   "source": [
    "### a. Working Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5b27c3-087a-4db1-8dfe-a78f241caa84",
   "metadata": {},
   "source": [
    "Cleaning the Corpus: In this step, we first convert the XML document into a text file for easier processing, generating an output file named output.txt. This file is then cleaned by removing unnecessary English words, numbers, URLs, and unwanted symbols, and the cleaned version is saved as cleaned_output.txt. Further cleaning is done by removing extra white spaces and lines, and replacing every '|' with a '| \\n' for better formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e94ed9-5e8f-4468-bc15-de0acc35180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open(r\"C:\\Users\\Anurag Khanna\\Desktop\\saharia\\cleaning.py\", 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "cleaned_text = re.sub(r'\\s+', ' ', text) \n",
    "cleaned_text =   cleaned_text.replace('।', '।\\n')\n",
    "cleaned_text = \"\\n\".join([line.strip() for line in cleaned_text.splitlines()])\n",
    "\n",
    "print(cleaned_text)\n",
    "\n",
    "with open(r\"C:\\Users\\Anurag Khanna\\Desktop\\saharia\\cleaning.py\", 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1643ce7a-1f21-4794-9087-085f9c1896fb",
   "metadata": {},
   "source": [
    "### b. Number of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50af85d-7e20-4f8d-ade1-166e0499d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentences = len(sentences)\n",
    "num_sentences-=1\n",
    "print(num_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899fe304-2daa-4a23-ad1c-b917d6d69dd7",
   "metadata": {},
   "source": [
    "### c. Display Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede15346-b9ff-40ef-9826-c9ea8a6542f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Anurag Khanna\\Desktop\\saharia\\cleaning.py\", 'r', encoding='utf-8') as file:\n",
    "    text = file.read().replace('॥', '।')\n",
    "\n",
    "sentences = text.split('।')\n",
    "\n",
    "for sentence in sentences[:50]:\n",
    "    print(sentence.strip()+ '।')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace531c1-dd21-4ea9-9d2a-0bd9329b1eee",
   "metadata": {},
   "source": [
    "## Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd77288-3b3f-4641-96eb-faa76e04fc96",
   "metadata": {},
   "source": [
    "### a. Cleanig the corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af541d5-e174-4aed-b63f-de0d5396e57d",
   "metadata": {},
   "source": [
    "### b. Number of Words and Characters in the Corpus\n",
    "In this step, we split the text using white spaces as the delimiter, which separates words in Hindi. To count the number of characters, we simply calculate the length of the entire text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a948606f-35f7-47f2-ac0c-23e927e05680",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split()\n",
    "\n",
    "number_of_words = len(words)\n",
    "print(f\"Number of Words are : {number_of_words}\")\n",
    "\n",
    "number_of_characters = len(text)\n",
    "print(f\"Number of Characters are : {number_of_characters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e98e2-b945-47fe-bce4-a3b41453f9e2",
   "metadata": {},
   "source": [
    "### c. Unigram and Bigram word with frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec90836-1ecb-4c0d-97d6-e21fda9c90fc",
   "metadata": {},
   "source": [
    "<h4> Unigram with Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3914a86-9c16-40b2-b3ae-40966ba69034",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq={}\n",
    "unigram =[]\n",
    "for word in words:\n",
    "    if word in freq:\n",
    "        freq[word]+=1\n",
    "    else:\n",
    "        freq[word]=1  \n",
    "\n",
    "for word, frequency in sorted(freq.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"{word}: {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35edcb9-1945-4cdc-8ae1-fe18af8cbfb5",
   "metadata": {},
   "source": [
    "<h4> Bigram with frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c0958-4676-4c12-9e3d-d2ff97e0b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_freq = {}\n",
    "bigram = []\n",
    "\n",
    "for i in range(len(words) - 1):\n",
    "    bigram = (words[i], words[i + 1])\n",
    "    if bigram in bigram_freq:\n",
    "        bigram_freq[bigram] += 1\n",
    "    else:\n",
    "        bigram_freq[bigram] = 1  \n",
    "        \n",
    "for bg, frequency in sorted(freq.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"{bg}: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fef0e-cb0d-418e-b1c1-7435b89c721b",
   "metadata": {},
   "source": [
    "### d. Print number of two letter words, three-letter word, four letter words and more than 4 letter words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4a186-778e-428d-af7a-0dd40f8ba780",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_letter=0\n",
    "three_letter=0\n",
    "four_letter=0\n",
    "more_than_four_letter=0\n",
    "\n",
    "for word in words:\n",
    "    if len(word)==2:\n",
    "        two_letter+=1\n",
    "    elif len(word)==3:\n",
    "        three_letter+=1\n",
    "    elif len(word)==4:\n",
    "        four_letter+=1\n",
    "    elif len(word)>4:\n",
    "        more_than_four_letter+=1\n",
    "\n",
    "print(f\"Number of two letter words: {two_letter}\\nNumber of three letter words: {three_letter}\\nNumber of four letter words: {four_letter}\\nNumber of more than four letter words: {more_than_four_letter}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c26b57-a819-46ca-8f86-84a17137979b",
   "metadata": {},
   "source": [
    "### e. Plot unigram word-frequency against the rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a5533-e07a-4094-975e-533fedd5d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sorted_freq = sorted(freq.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "frequencies = [item[1] for item in sorted_freq]\n",
    "ranks = range(1, len(frequencies) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ranks, frequencies, marker='o')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Rank (log scale)')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.title('Unigram Word-Frequency vs. Rank (Zipf\\'s Law)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6dc7e-7986-4c72-8f91-42ee8c2ef70d",
   "metadata": {},
   "source": [
    "# Phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e73bc1-72b8-4dd8-98a3-e92b957c67a6",
   "metadata": {},
   "source": [
    "### a. Unigram, Bi-gram and Trigram character frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce7a77-2f36-4d16-aa3a-5e7b25544ff1",
   "metadata": {},
   "source": [
    "<h4> Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749bd00a-44ac-4eb3-97fe-799954fd71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_freq = {}\n",
    "\n",
    "# Count frequency of each character (unigram)\n",
    "for char in text:  # 'text' contains the entire string\n",
    "    if char in unigram_freq:\n",
    "        unigram_freq[char] += 1\n",
    "    else:\n",
    "        unigram_freq[char] = 1\n",
    "\n",
    "# Sort based on frequency in descending order and print\n",
    "for char, frequency in sorted(unigram_freq.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"{char}: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9ebe5-3952-4376-96df-074e5c2c1889",
   "metadata": {},
   "source": [
    "<h4> Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a958f49-3a87-403f-b5c1-7990d116db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_freq = {}\n",
    "\n",
    "# Create bigrams and count their frequency\n",
    "for i in range(len(text) - 1):\n",
    "    bigram = text[i:i+2]\n",
    "    if bigram in bigram_freq:\n",
    "        bigram_freq[bigram] += 1\n",
    "    else:\n",
    "        bigram_freq[bigram] = 1\n",
    "\n",
    "# Sort based on frequency in descending order and print\n",
    "for bigram, frequency in sorted(bigram_freq.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"{bigram}: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd438d-bf6d-4f82-9b38-caafd70a7321",
   "metadata": {},
   "source": [
    "<h4> Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff6793-52cb-4e37-ae36-86d826a5836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_freq = {}\n",
    "\n",
    "# Create trigrams and count their frequency\n",
    "for i in range(len(text) - 2):\n",
    "    trigram = text[i:i+3]\n",
    "    if trigram in trigram_freq:\n",
    "        trigram_freq[trigram] += 1\n",
    "    else:\n",
    "        trigram_freq[trigram] = 1\n",
    "\n",
    "# Sort based on frequency in descending order and print\n",
    "for trigram, frequency in sorted(trigram_freq.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"{trigram}: {frequency}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
